SOCRAT-AI üéì
Socrat-AI es un tutor acad√©mico dise√±ado para guiar a los estudiantes sin entregar respuestas directas. Utiliza el m√©todo socr√°tico para fomentar el pensamiento cr√≠tico, validando la entrada del usuario contra r√∫bricas de evaluaci√≥n y detectando intentos de fraude acad√©mico mediante una arquitectura de agentes multi-nodo.

üèóÔ∏è Arquitectura y Decisiones T√©cnicas
El Modelo
Se seleccion√≥ la familia Gemini de Google por su baja latencia y alta precisi√≥n en razonamiento l√≥gico.

Modelo Principal: gemini-1.5-flash (seleccionado por su excelente trade-off entre velocidad y rendimiento para tareas de tutor√≠a en tiempo real).

Razonamiento: La capacidad del modelo para seguir instrucciones complejas y manejar salidas estructuradas fue determinante para la l√≥gica de los nodos de control.

El Stack
FastAPI: Elegido por su manejo nativo de asincron√≠a, vital para mitigar la latencia de APIs externas.

Pydantic: Motor central para la validaci√≥n de contratos de datos y la estructuraci√≥n de las salidas de los LLMs.

LangGraph: Implementado para orquestar un flujo de agente c√≠clico y controlado, permitiendo validaciones granulares que un simple System Prompt no podr√≠a garantizar.

Gemini Files API: Utilizado para el procesamiento eficiente y econ√≥mico de documentos (PDF/Docx) adjuntos por el alumno.

Loguru: Gesti√≥n de logs para trazabilidad y debugging en desarrollo.

üõ°Ô∏è Estrategia Anti-Fraude (Guardrails)
En lugar de confiar en un √∫nico prompt masivo propenso a prompt injection, el sistema utiliza una estructura de nodos especializados:

Nodo Guardi√°n (Pre-An√°lisis): Eval√∫a la intenci√≥n del usuario. Si detecta un intento de obtener la respuesta directa o plagio, detiene el flujo.

Nodo Tutor: Genera la gu√≠a pedag√≥gica basada en la r√∫brica y la metodolog√≠a socr√°tica.

Nodo de Post-An√°lisis: Un revisor independiente verifica que la respuesta del tutor no haya filtrado accidentalmente la soluci√≥n y que cumpla con los est√°ndares de calidad.

Flujo de Trabajo
Fragmento de c√≥digo

graph TD
    %% Nodos principales
    Start((Inicio)) --> PreAnalysis[Pre-An√°lisis]
    
    %% Decisiones del Nodo de Pre-An√°lisis
    PreAnalysis -- "Fraude / Riesgo Alto" --> NegativeFeedback[Feedback Negativo]
    PreAnalysis -- "Seguro" --> Tutor[Tutor IA]
    
    %% Proceso de Tutor√≠a
    Tutor --> PostAnalysis[Post-An√°lisis]
    
    %% Decisiones del Nodo de Post-An√°lisis
    PostAnalysis -- "V√°lido" --> End((Fin))
    PostAnalysis -- "No V√°lido" --> NegativeFeedback
    
    %% Salida final de error
    NegativeFeedback --> End

    %% Estilizado
    style Start fill:#f9f9f9,stroke:#333,stroke-width:2px
    style End fill:#bfb6fc,stroke:#333,stroke-width:4px
    style PreAnalysis fill:#e1f5fe,stroke:#01579b
    style Tutor fill:#e8f5e9,stroke:#2e7d32
    style PostAnalysis fill:#fff3e0,stroke:#ef6c00
    style NegativeFeedback fill:#ffebee,stroke:#c62828
üìã Contratos de Datos (Pydantic Models)
El sistema se comunica mediante estructuras estrictas para asegurar la integridad de los datos entre nodos.

PreAnalysisJudge: Determina el nivel de riesgo (1-5) y la detecci√≥n de trampas.

AnalysisResult: Contiene el Chain of Thought, el output final y los Anchor References (citas directas de la r√∫brica).

TutorState: El objeto de estado global que persiste la informaci√≥n a trav√©s del grafo de LangGraph.

Python

class AnalysisResult(BaseModel):
    chain_of_thought: str = Field(..., description="Razonamiento l√≥gico del tutor")
    anchor_references: list[str] = Field(..., description="Fragmentos de la r√∫brica utilizados")
    output: str = Field(..., description="Respuesta socr√°tica final")
üß† Metodolog√≠a de Prompting
Se implementaron t√©cnicas de ingenier√≠a de prompts de √∫ltima generaci√≥n para maximizar la fiabilidad:

Grounding Anchors: Se obliga al modelo a citar textualmente la r√∫brica o las instrucciones para reducir alucinaciones.

Chain of Thought (CoT): Cada nodo debe "pensar en voz alta" antes de entregar un resultado, mejorando la coherencia en tareas complejas.

Decisiones Booleanas: Forzamos al modelo a tomar posturas binarias (¬øEs trampa? S√≠/No) para evitar ambig√ºedades en la l√≥gica de control.

Separaci√≥n de Responsabilidades: Cada prompt se enfoca exclusivamente en una tarea (validar, ense√±ar o revisar), reduciendo la carga cognitiva del modelo.

üöÄ Instalaci√≥n y Uso
Local
Clona el repositorio: git clone ...

Instala dependencias: pip install -r requirements.txt

Configura tus variables de entorno en un archivo .env:

Fragmento de c√≥digo

GOOGLE_API_KEY=tu_api_key
Ejecuta la aplicaci√≥n: uvicorn main:app --reload

Docker
Bash

docker build -t socrat-ai .
docker run -p 8000:8000 --env-file .env socrat-ai
üõ†Ô∏è API Endpoints
POST /tutor/analyze: Recibe el prompt, la r√∫brica y archivos adjuntos (multipart).

200 OK: Retorna la respuesta del tutor.

429 Too Many Requests: L√≠mite de cuota de Gemini alcanzado.

500 Internal Error: Error inesperado en el procesamiento.
